{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "\n",
    "project_path = './drive/MyDrive/multi_gait_project'\n",
    "dataset_dir = project_path + \"/SMVDU-Single-Gait\"\n",
    "final_dataset_dir = project_path + \"/dataset\"\n",
    "\n",
    "movenet = hub.load(\"https://tfhub.dev/google/movenet/singlepose/lightning/4\")\n",
    "movenet = movenet.signatures['serving_default']\n",
    "\n",
    "\n",
    "def get_keypoints(image):\n",
    "    img = cv2.imread(image)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = tf.convert_to_tensor(img)\n",
    "    img = tf.image.resize_with_pad(img, 192, 192)\n",
    "    img = tf.cast(img, dtype=tf.int32)\n",
    "    img = tf.expand_dims(img, axis=0)\n",
    "    outputs = movenet(img)\n",
    "    keypoints = outputs['output_0']\n",
    "    return keypoints\n",
    "\n",
    "# drawing keypoints \n",
    "def draw_keypoints(image, keypoints):\n",
    "    img = cv2.imread(image)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, (192, 192))\n",
    "    for i in range(keypoints.shape[1]):\n",
    "        x = int(keypoints[0][i][0])\n",
    "        y = int(keypoints[0][i][1])\n",
    "        cv2.circle(img, (x, y), 2, (0, 255, 0), 2)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Trying to load a model of incompatible/unknown type. 'C:\\Users\\priya\\AppData\\Local\\Temp\\tfhub_modules\\312f001449331ee3d410d758fccdc9945a65dbc3' contains neither 'saved_model.pb' nor 'saved_model.pbtxt'.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m movenet \u001b[38;5;241m=\u001b[39m \u001b[43mhub\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhttps://tfhub.dev/google/movenet/multipose/lightning/1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m movenet \u001b[38;5;241m=\u001b[39m movenet\u001b[38;5;241m.\u001b[39msignatures[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mserving_default\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      5\u001b[0m keypoint_names \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnose\u001b[39m\u001b[38;5;124m'\u001b[39m,  \u001b[38;5;66;03m# 0\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft_eye\u001b[39m\u001b[38;5;124m'\u001b[39m,  \u001b[38;5;66;03m# 1\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mright_ankle\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;66;03m# 16\u001b[39;00m\n\u001b[0;32m     23\u001b[0m     ]\n",
      "File \u001b[1;32me:\\envs\\miniconda\\envs\\tf\\lib\\site-packages\\tensorflow_hub\\module_v2.py:113\u001b[0m, in \u001b[0;36mload\u001b[1;34m(handle, tags, options)\u001b[0m\n\u001b[0;32m    108\u001b[0m saved_model_pbtxt_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[0;32m    109\u001b[0m     tf\u001b[38;5;241m.\u001b[39mcompat\u001b[38;5;241m.\u001b[39mas_bytes(module_path),\n\u001b[0;32m    110\u001b[0m     tf\u001b[38;5;241m.\u001b[39mcompat\u001b[38;5;241m.\u001b[39mas_bytes(tf\u001b[38;5;241m.\u001b[39msaved_model\u001b[38;5;241m.\u001b[39mSAVED_MODEL_FILENAME_PBTXT))\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mgfile\u001b[38;5;241m.\u001b[39mexists(saved_model_path) \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mgfile\u001b[38;5;241m.\u001b[39mexists(saved_model_pbtxt_path)):\n\u001b[1;32m--> 113\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrying to load a model of incompatible/unknown type. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    114\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m contains neither \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m nor \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m    115\u001b[0m                    (module_path, tf\u001b[38;5;241m.\u001b[39msaved_model\u001b[38;5;241m.\u001b[39mSAVED_MODEL_FILENAME_PB,\n\u001b[0;32m    116\u001b[0m                     tf\u001b[38;5;241m.\u001b[39msaved_model\u001b[38;5;241m.\u001b[39mSAVED_MODEL_FILENAME_PBTXT))\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m options:\n\u001b[0;32m    119\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mgetattr\u001b[39m(tf, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msaved_model\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoadOptions\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "\u001b[1;31mValueError\u001b[0m: Trying to load a model of incompatible/unknown type. 'C:\\Users\\priya\\AppData\\Local\\Temp\\tfhub_modules\\312f001449331ee3d410d758fccdc9945a65dbc3' contains neither 'saved_model.pb' nor 'saved_model.pbtxt'."
     ]
    }
   ],
   "source": [
    "movenet = hub.load(\"https://tfhub.dev/google/movenet/multipose/lightning/1\")\n",
    "movenet = movenet.signatures['serving_default']\n",
    "\n",
    "\n",
    "keypoint_names = [\n",
    "    'nose',  # 0\n",
    "    'left_eye',  # 1\n",
    "    'right_eye', # 2\n",
    "    'left_ear', # 3\n",
    "    'right_ear', # 4\n",
    "    'left_shoulder', # 5 \n",
    "    'right_shoulder', # 6\n",
    "    'left_elbow', # 7\n",
    "    'right_elbow', # 8\n",
    "    'left_wrist', # 9\n",
    "    'right_wrist', # 10\n",
    "    'left_hip', # 11\n",
    "    'right_hip', # 12\n",
    "    'left_knee', # 13\n",
    "    'right_knee', # 14\n",
    "    'left_ankle', # 15\n",
    "    'right_ankle' # 16\n",
    "    ]\n",
    "\n",
    "keypoints_to_detect = [\n",
    "    5, # left shoulder\n",
    "    7, # left elbow\n",
    "    9, # left wrist\n",
    "    13, # left knee\n",
    "    15, # left ankle\n",
    "]\n",
    "\n",
    "def get_main_keypoints(frame, keypoints, confidence_threshold, keypoints_to_detect=keypoints_to_detect):\n",
    "    y, x, c = frame.shape\n",
    "    shaped = np.squeeze(np.multiply(keypoints, [y,x,1]))\n",
    "    keypoints_coordinates = {}\n",
    "    for kp in keypoints_to_detect:\n",
    "        ky, kx, kp_conf = shaped[kp]\n",
    "        if kp_conf > confidence_threshold:\n",
    "            keypoints_coordinates[keypoint_names[kp]] = (int(kx), int(ky))\n",
    "    # print(keypoints_coordinates)\n",
    "    return keypoints_coordinates\n",
    "\n",
    "def loop_through_people_main_keypoints(frame, keypoints_with_scores, confidence_threshold):\n",
    "    person_main_keypoints = []\n",
    "    for person in keypoints_with_scores[:1]:\n",
    "        person_main_keypoints.append(get_main_keypoints(frame, person, confidence_threshold))\n",
    "    return person_main_keypoints\n",
    "\n",
    "def get_main_keypoints_from_video(video_path, confidence_threshold):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    # start video from 1 second \n",
    "    # cap.set(cv2.CAP_PROP_POS_MSEC, 1000)\n",
    "    i = 0\n",
    "    scale = 1\n",
    "    person_main_keypoints_sequence = {}\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        i += 1\n",
    "        if not ret:\n",
    "            break\n",
    "        if i % 1 == 0:\n",
    "            frame = frame[:, :, ::-1]\n",
    "            frame = cv2.resize(frame, (256*scale, 256*scale))\n",
    "            keypoints_with_scores = get_keypoints(frame)\n",
    "            person_main_keypoints = loop_through_people_main_keypoints(frame, keypoints_with_scores, confidence_threshold)\n",
    "            for person, pmkp in enumerate(person_main_keypoints):\n",
    "                if person not in person_main_keypoints_sequence:\n",
    "                    person_main_keypoints_sequence[person] = {}\n",
    "                for keypoint, coordinates in pmkp.items():\n",
    "                    if keypoint not in person_main_keypoints_sequence[person]:\n",
    "                        person_main_keypoints_sequence[person][keypoint] = []\n",
    "                    # coordinates = (coordinates[0]/256.0, coordinates[1]/256.0)\n",
    "                    person_main_keypoints_sequence[person][keypoint].append(coordinates)\n",
    "    #         \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    return person_main_keypoints_sequence\n",
    "\n",
    "\n",
    "dataset_folder = 'dataset/SMVDU-Single-Gait'\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "for video in os.listdir(dataset_folder):\n",
    "    x = video.split('_')\n",
    "    # if x[1][0] == '1' : \n",
    "    video_path = os.path.join(dataset_folder, video)\n",
    "    person_main_keypoints_sequence = get_main_keypoints_from_video(video_path, 0)\n",
    "    model_inp_matrix = []\n",
    "    for mkp in keypoints_to_detect :\n",
    "        x = person_main_keypoints_sequence[0][keypoint_names[mkp]]\n",
    "        model_inp_matrix.append(x)\n",
    "    model_inp_matrix = np.array(model_inp_matrix)\n",
    "    model_inp_matrix = model_inp_matrix[:, 150:300]\n",
    "    model_inp_matrix = np.reshape(model_inp_matrix, (model_inp_matrix.shape[0], model_inp_matrix.shape[1], 2))\n",
    "    with open('numpy_dataset/' + video + '.pkl', 'wb') as f:\n",
    "        pickle.dump(model_inp_matrix, f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0\n",
      "0.16.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "print(tf.__version__)\n",
    "print(hub.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
